# ========== PHáº¦N 1: Váº¼ Máº NG NGÆ¯á»œI DÃ™NG - Sáº¢N PHáº¨M ==========
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt

file_path = "./transactions_top1000cust_top500articles.csv"
df = pd.read_csv(file_path)
df = df[(df['customer_id'].notna()) & df['prod_name'].notna()]

# Giá»¯ láº¡i top 50 ngÆ°á»i dÃ¹ng vÃ  50 sáº£n pháº©m
#top_users = df['customer_id'].value_counts().nlargest(500).index
#top_items = df['prod_name'].value_counts().nlargest(500).index
#df_filtered = df[df['customer_id'].isin(top_users) & df['prod_name'].isin(top_items)]
df_filtered = df
# Táº¡o Ä‘á»“ thá»‹ báº±ng NetworkX
G = nx.Graph()
for row in df_filtered.itertuples():
    user = f"user_{row.customer_id}"
    item = f"item_{row.prod_name}"
    G.add_node(user, type='user')
    G.add_node(item, type='item')
    G.add_edge(user, item)

# TÃ­nh Ä‘á»™ lá»›n nÃºt
user_counts = df_filtered.groupby("customer_id")["total"].sum().to_dict()
item_counts = df_filtered.groupby("prod_name")["total"].sum().to_dict()
node_sizes = []
node_colors = []
for node in G.nodes():
    if node.startswith("user_"):
        uid = node.replace("user_", "")
        size = user_counts.get(uid, 1)
        node_sizes.append(size * 10)
        node_colors.append("skyblue")
    else:
        iid = node.replace("item_", "")
        size = item_counts.get(iid, 1)
        node_sizes.append(size * 10)
        node_colors.append("lightgreen")

# Váº½ máº¡ng
plt.figure(figsize=(7, 7))
pos = nx.spring_layout(G, k=0.2)
nx.draw(G, pos, node_size=node_sizes, node_color=node_colors, edge_color='gray', alpha=0.7, with_labels=False)
plt.title("Máº¡ng ngÆ°á»i dÃ¹ng - sáº£n pháº©m")
plt.savefig("mang.jpg", dpi=300, bbox_inches='tight')
plt.show()

#cÃ i cÃ¡c thÆ° viá»‡n Ä‘á»ƒ cháº¡y GNN chá»‰ cáº§n cháº¡y láº§n Ä‘áº§u tiÃªn thÃ´i
!pip install torch torchvision torchaudio
import torch
print(torch.__version__)
print("âœ… PyTorch Ä‘Ã£ Ä‘Æ°á»£c cÃ i thÃ nh cÃ´ng!")
!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html
!pip install torch-geometric
import torch_geometric
print("âœ… torch_geometric Ä‘Ã£ Ä‘Æ°á»£c cÃ i thÃ nh cÃ´ng!")

# ========== PHáº¦N 2: GNN Dá»° ÄOÃN Máº¶T HÃ€NG ==========
import torch
import torch.nn.functional as F
from torch_geometric.data import Data
from torch_geometric.nn import GCNConv

# Táº¡o Ã¡nh xáº¡ ID -> sá»‘ nguyÃªn liÃªn tá»¥c
user_ids = df_filtered['customer_id'].unique()
item_ids = df_filtered['prod_name'].unique()
user_map = {uid: i for i, uid in enumerate(user_ids)}
item_map = {iid: i+len(user_ids) for i, iid in enumerate(item_ids)}

# Táº¡o danh sÃ¡ch cáº¡nh
edges = []
for row in df_filtered.itertuples():
    u = user_map[row.customer_id]
    i = item_map[row.prod_name]
    edges.append([u, i])
    edges.append([i, u])

edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()

# One-hot vector cho má»—i node
num_nodes = len(user_map) + len(item_map)
x = torch.eye(num_nodes, dtype=torch.float)
data = Data(x=x, edge_index=edge_index)

# GCN model
class GCN(torch.nn.Module):
    def __init__(self, in_channels, hidden_channels):
        super(GCN, self).__init__()
        self.conv1 = GCNConv(in_channels, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, hidden_channels)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.conv2(x, edge_index)
        return x

model = GCN(in_channels=num_nodes, hidden_channels=32)
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# Negative sampling Ä‘Æ¡n giáº£n
def negative_sampling(edge_index, num_nodes, num_samples):
    neg_edges = set()
    edges = set(tuple(e) for e in edge_index.t().tolist())
    while len(neg_edges) < num_samples:
        i = torch.randint(0, num_nodes, (1,)).item()
        j = torch.randint(0, num_nodes, (1,)).item()
        if i != j and (i, j) not in edges and (j, i) not in edges:
            neg_edges.add((i, j))
    return torch.tensor(list(neg_edges), dtype=torch.long).t()

# Táº¡o táº­p huáº¥n luyá»‡n
num_pos = edge_index.size(1)
neg_edge_index = negative_sampling(edge_index, num_nodes, num_pos)

def get_link_labels(pos_edge_index, neg_edge_index):
    return torch.cat([
        torch.ones(pos_edge_index.size(1)),
        torch.zeros(neg_edge_index.size(1))
    ])

def compute_loss(z, pos_edge_index, neg_edge_index):
    total_edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=1)
    z_i = z[total_edge_index[0]]
    z_j = z[total_edge_index[1]]
    pred = (z_i * z_j).sum(dim=1)
    labels = get_link_labels(pos_edge_index, neg_edge_index)
    return F.binary_cross_entropy_with_logits(pred, labels)

# Train model
model.train()
for epoch in range(1, 51):
    optimizer.zero_grad()
    z = model(data.x, edge_index)
    loss = compute_loss(z, edge_index, neg_edge_index)
    loss.backward()
    optimizer.step()
    if epoch % 10 == 0:
        print(f"Epoch {epoch}, Loss: {loss.item():.4f}")

# Dá»± Ä‘oÃ¡n sáº£n pháº©m tiáº¿p theo cho má»™t ngÆ°á»i dÃ¹ng cá»¥ thá»ƒ
model.eval()
with torch.no_grad():
    z = model(data.x, edge_index)
    test_user = list(user_map.keys())[0]
    user_idx = user_map[test_user]
    print(f"\nDá»± Ä‘oÃ¡n máº·t hÃ ng tiáº¿p theo cho ngÆ°á»i dÃ¹ng: {test_user}\n")
    scores = []
    for item, item_idx in item_map.items():
        score = (z[user_idx] * z[item_idx]).sum().item()
        scores.append((item, score))

    top_items = sorted(scores, key=lambda x: x[1], reverse=True)[:10]
    for item, score in top_items:
        print(f"{item} | score: {score:.4f}")

# ===== TÃNH CÃC CHá»ˆ Sá» CENTRALITY =====
deg_centrality = nx.degree_centrality(G)
btw_centrality = nx.betweenness_centrality(G)
eig_centrality = nx.eigenvector_centrality(G, max_iter=500)

# Gom láº¡i thÃ nh DataFrame
centrality_df = pd.DataFrame({
    'node': list(G.nodes()),
    'degree': [deg_centrality[n] for n in G.nodes()],
    'betweenness': [btw_centrality[n] for n in G.nodes()],
    'eigenvector': [eig_centrality[n] for n in G.nodes()],
    'type': ['user' if n.startswith('user_') else 'item' for n in G.nodes()]
})

# ===== TOP 10 THEO Tá»ªNG CHá»ˆ Sá» - TOÃ€N Máº NG =====
print("ðŸ”¹ Top 10 node theo Degree Centrality:")
print(centrality_df.sort_values(by='degree', ascending=False).head(10)[['node', 'type', 'degree']])

print("\nðŸ”¹ Top 10 node theo Betweenness Centrality:")
print(centrality_df.sort_values(by='betweenness', ascending=False).head(10)[['node', 'type', 'betweenness']])

print("\nðŸ”¹ Top 10 node theo Eigenvector Centrality:")
print(centrality_df.sort_values(by='eigenvector', ascending=False).head(10)[['node', 'type', 'eigenvector']])

# ===== TOP 10 KHÃCH HÃ€NG THEO Tá»ªNG CHá»ˆ Sá» =====
user_df = centrality_df[centrality_df['type'] == 'user']

print("\nðŸ‘¤ Top 10 KHÃCH HÃ€NG theo Degree Centrality:")
print(user_df.sort_values(by='degree', ascending=False).head(10)[['node', 'degree']])

print("\nðŸ‘¤ Top 10 KHÃCH HÃ€NG theo Betweenness Centrality:")
print(user_df.sort_values(by='betweenness', ascending=False).head(10)[['node', 'betweenness']])

print("\nðŸ‘¤ Top 10 KHÃCH HÃ€NG theo Eigenvector Centrality:")
print(user_df.sort_values(by='eigenvector', ascending=False).head(10)[['node', 'eigenvector']])

!pip install python-louvain

import community.community_louvain as community_louvain

# Cháº¡y thuáº­t toÃ¡n Louvain Ä‘á»ƒ phÃ¢n cá»¥m
partition = community_louvain.best_partition(G)

# ========== PHáº¦N 2: PAGERANK TRONG Tá»ªNG Cá»˜NG Äá»’NG ==========
# TÃ­nh PageRank toÃ n máº¡ng
from collections import defaultdict
pagerank = nx.pagerank(G)

# Gom cÃ¡c sáº£n pháº©m theo cá»™ng Ä‘á»“ng
community_items = defaultdict(list)
for node, group in partition.items():
    if node.startswith("item_"):
        community_items[group].append(node)

# In top sáº£n pháº©m cÃ³ PageRank cao nháº¥t theo tá»«ng cá»™ng Ä‘á»“ng
for com, items in community_items.items():
    top_items = sorted(items, key=lambda x: pagerank[x], reverse=True)[:5]
    print(f"\nðŸŽ¯ Cá»™ng Ä‘á»“ng {com} â€“ sáº£n pháº©m hot theo PageRank:")
    for item in top_items:
        print(f" - {item.replace('item_', '')} | PageRank: {pagerank[item]:.4f}")

# ========== PHáº¦N 1: CLUSTERING (Louvain) Cá»˜NG Äá»’NG ==========

import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
from collections import defaultdict
import community.community_louvain as community_louvain

# Äá»c dá»¯ liá»‡u vÃ  xá»­ lÃ½
#file_path = "./transactions_top1000cust_top500articles.csv"
#df = pd.read_csv(file_path)
#df = df[(df['customer_id'].notna()) & df['prod_name'].notna()]
top_users = df['customer_id'].value_counts().nlargest(1000).index
top_items = df['prod_name'].value_counts().nlargest(50).index
df_filtered = df[df['customer_id'].isin(top_users) & df['prod_name'].isin(top_items)]

# Táº¡o Ä‘á»“ thá»‹ hai lá»›p
G = nx.Graph()
for row in df_filtered.itertuples():
    user = f"user_{row.customer_id}"
    item = f"item_{row.prod_name}"
    G.add_node(user, type='user')
    G.add_node(item, type='item')
    G.add_edge(user, item)

# Ãnh xáº¡ cá»™ng Ä‘á»“ng báº±ng Louvain
partition = community_louvain.best_partition(G)
nx.set_node_attributes(G, partition, name='community')

# Trá»±c quan hÃ³a máº¡ng theo cá»™ng Ä‘á»“ng
colors = [partition[n] for n in G.nodes()]
pos = nx.spring_layout(G, k=0.2)
plt.figure(figsize=(7, 7))
nx.draw(G, pos, node_color=colors, with_labels=False, node_size=50, cmap=plt.cm.Set3)
plt.title("Máº¡ng ngÆ°á»i dÃ¹ng â€“ sáº£n pháº©m phÃ¢n theo cá»™ng Ä‘á»“ng (Louvain)")
plt.savefig("clusters_Louvain.jpg", dpi=300, bbox_inches='tight')
plt.show()

# ========== PHáº¦N 3: Váº¼ Tá»ªNG Cá»˜NG Äá»’NG RIÃŠNG BIá»†T ==========
import math

# XÃ¡c Ä‘á»‹nh sá»‘ lÆ°á»£ng cá»™ng Ä‘á»“ng
unique_communities = sorted(set(partition.values()))
num_coms = len(unique_communities)

# Táº¡o figure chia nhá» theo subplot
cols = 2  # sá»‘ cá»™t hÃ¬nh
rows = math.ceil(num_coms / cols)
fig, axes = plt.subplots(rows, cols, figsize=(cols * 6, rows * 5))

# Äáº£m báº£o axes lÃ  dáº¡ng máº£ng pháº³ng
axes = axes.flatten()

for i, com in enumerate(unique_communities):
    ax = axes[i]
    sub_nodes = [n for n in G.nodes() if partition[n] == com]
    subgraph = G.subgraph(sub_nodes)
    sub_pos = nx.spring_layout(subgraph, k=0.3)
    node_colors = ['skyblue' if n.startswith("user_") else 'lightgreen' for n in subgraph.nodes()]
    nx.draw(subgraph, sub_pos, ax=ax, node_color=node_colors, with_labels=False, node_size=60)
    ax.set_title(f"Cá»™ng Ä‘á»“ng {com} ({len(subgraph.nodes())} nÃºt)")
    ax.axis('off')

# áº¨n Ã´ trá»‘ng náº¿u sá»‘ subplot láº»
for j in range(i + 1, len(axes)):
    axes[j].axis('off')

plt.tight_layout()
plt.savefig("clusters.jpg", dpi=300, bbox_inches='tight')
plt.show()

# ========== Gá»¢I Ã Sáº¢N PHáº¨M THEO Cá»¤M NGÆ¯á»œI DÃ™NG (DÃ™ ÄÃƒ MUA) ==========
from collections import defaultdict

# Gom user theo cá»™ng Ä‘á»“ng
community_users = defaultdict(list)
for node, com in partition.items():
    if node.startswith("user_"):
        community_users[com].append(node)

# Gom sáº£n pháº©m theo cá»™ng Ä‘á»“ng
community_items = defaultdict(list)
for node, com in partition.items():
    if node.startswith("item_"):
        community_items[com].append(node)

# Gá»£i Ã½ sáº£n pháº©m PageRank cao trong cá»™ng Ä‘á»“ng â€“ cÃ³ thá»ƒ Ä‘Ã£ mua
for com in sorted(community_users.keys()):
    users = community_users[com]
    all_items_in_com = community_items.get(com, [])

    if not all_items_in_com:
        print(f"\nâš ï¸ KhÃ´ng cÃ³ sáº£n pháº©m trong cá»™ng Ä‘á»“ng {com}")
        continue

    # Æ¯u tiÃªn sáº£n pháº©m theo PageRank cao trong cá»¥m
    top_suggestions = sorted(all_items_in_com, key=lambda x: pagerank.get(x, 0), reverse=True)[:5]

    print(f"\nðŸŽ¯ Gá»£i Ã½ sáº£n pháº©m cho cá»™ng Ä‘á»“ng {com} (theo PageRank):")
    for item in top_suggestions:
        print(f" - {item.replace('item_', '')} | PageRank: {pagerank.get(item):.4f}")

